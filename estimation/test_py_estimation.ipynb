{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy.optimize import minimize\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "df_reviews = pd.read_csv('../data/movie_reviews.csv').dropna()\n",
    "df_reviews_pr = pd.read_csv('../data/movie_reviews_processed.csv').dropna()\n",
    "model_reviews = sm.load('../linear_models/data/model_reviews.pickle') # pkl later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_happiness = (\n",
    "    pd.read_csv('../data/world_happiness_2018.csv')\n",
    "    .dropna()\n",
    "    .rename(\n",
    "        columns = {\n",
    "            'happiness_score': 'happiness',\n",
    "            'healthy_life_expectancy_at_birth': 'life_exp',\n",
    "            'log_gdp_per_capita': 'log_gdp_pc',\n",
    "            'perceptions_of_corruption': 'corrupt'\n",
    "        }\n",
    "    )\n",
    "    .assign(\n",
    "        gdp_pc = lambda x: np.exp(x['log_gdp_pc']),\n",
    "    )\n",
    "    [['country', 'happiness', 'life_exp', 'gdp_pc', 'corrupt']]\n",
    ")\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df_happiness[['life_exp', 'gdp_pc', 'corrupt']] = scaler.fit_transform(\n",
    "    df_happiness[['life_exp', 'gdp_pc', 'corrupt']]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.793842044979073"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ols(par, X, y, sum = False):\n",
    "    # add a column of 1s for the intercept\n",
    "    X = np.c_[np.ones(X.shape[0]), X]\n",
    "\n",
    "    # Calculate the predicted values\n",
    "    y_hat = X @ par\n",
    "    \n",
    "    # Calculate the error\n",
    "    value = np.sum((y - y_hat)**2)\n",
    "    \n",
    "    # Calculate the value as sum or average\n",
    "    if not sum:\n",
    "        value = value / X.shape[0]\n",
    "    \n",
    "    # Return the value\n",
    "    return(value)\n",
    "\n",
    "# create a grid of guesses\n",
    "from itertools import product\n",
    "\n",
    "guesses = pd.DataFrame(\n",
    "    product(\n",
    "        np.arange(1, 7, 0.1),\n",
    "        np.arange(-1, 1, 0.1)\n",
    "    ),\n",
    "    columns = ['b0', 'b1']\n",
    ")\n",
    "\n",
    "# Example for one guess\n",
    "ols(\n",
    "    par = guesses.iloc[0,:],\n",
    "    X = df_happiness['life_exp'],\n",
    "    y = df_happiness['happiness']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  message: Optimization terminated successfully.\n",
       "  success: True\n",
       "   status: 0\n",
       "      fun: 0.48851727833540676\n",
       "        x: [ 5.445e+00  8.838e-01]\n",
       "      nit: 3\n",
       "      jac: [-9.313e-08  7.004e-07]\n",
       " hess_inv: [[ 5.190e-01 -9.564e-02]\n",
       "            [-9.564e-02  9.810e-01]]\n",
       "     nfev: 12\n",
       "     njev: 4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "our_result = minimize(\n",
    "    fun    = ols,\n",
    "    x0     = np.array([1., 0.]),\n",
    "    args   = (np.array(df_happiness['life_exp']), np.array(df_happiness['happiness'])),\n",
    "    method = 'BFGS' # optimization algorithm\n",
    ")\n",
    "\n",
    "\n",
    "our_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10798193, 0.22184167])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "# two example life expectancy scores, mean and 1 sd above\n",
    "life_expectancy = np.array([0, 1])\n",
    "\n",
    "# observed happiness scores\n",
    "happiness = np.array([4, 5.2])\n",
    "\n",
    "# predicted happiness with rounded coefs\n",
    "mu = 5 + 1 * life_expectancy\n",
    "\n",
    "# just a guess for sigma\n",
    "sigma = .5\n",
    "\n",
    "# likelihood for each observation\n",
    "L = norm.pdf(happiness, loc = mu, scale = sigma)\n",
    "L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MaxLike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood(par, X, y):\n",
    "    # add a column of 1s for the intercept\n",
    "    X = np.c_[np.ones(X.shape[0]), X]\n",
    "\n",
    "    # setup\n",
    "    beta   = par[1:]       # coefficients\n",
    "    sigma  = np.exp(par[0])        # error sd\n",
    "\n",
    "    N = X.shape[0]\n",
    "\n",
    "    LP = X @ beta          # linear predictor\n",
    "    mu = LP                # identity link in the glm sense\n",
    "\n",
    "    # calculate (log) likelihood\n",
    "    ll = norm.logpdf(y, loc = mu, scale = sigma) \n",
    "    return(-np.sum(ll))\n",
    "\n",
    "our_result = minimize(\n",
    "    fun    = likelihood,\n",
    "    x0     = np.array([1, 0, 0]),\n",
    "    args   = (np.array(df_happiness['life_exp']), np.array(df_happiness['happiness'])),\n",
    "    # method = \"Nelder-Mead\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  message: Optimization terminated successfully.\n",
       "  success: True\n",
       "   status: 0\n",
       "      fun: 118.80381119428438\n",
       "        x: [-3.582e-01  5.445e+00  8.838e-01]\n",
       "      nit: 14\n",
       "      jac: [-1.907e-06  0.000e+00  9.537e-07]\n",
       " hess_inv: [[ 4.600e-03 -1.529e-04  9.976e-05]\n",
       "            [-1.529e-04  4.642e-03 -8.236e-05]\n",
       "            [ 9.976e-05 -8.236e-05  4.459e-03]]\n",
       "     nfev: 88\n",
       "     njev: 22"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Penalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (436664752.py, line 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[44], line 20\u001b[0;36m\u001b[0m\n\u001b[0;31m    np.array(df_happiness |> drop(['happiness', 'country'])),\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def ridge(par, X, y, lambda_ = 0):\n",
    "    # add a column of 1s for the intercept\n",
    "    X = np.c_[np.ones(X.shape[0]), X]\n",
    "\n",
    "    # Calculate the predicted values\n",
    "    mu = X @ par\n",
    "    \n",
    "    # Calculate the error\n",
    "    value = np.sum((y - mu)**2)\n",
    "    \n",
    "    # Add the penalty\n",
    "    value = value + lambda_ * np.sum(par**2)\n",
    "    \n",
    "    return(value)\n",
    "\n",
    "our_result = minimize(\n",
    "    fun  = ridge,\n",
    "    x0   = np.array([0, 0, 0, 0]),\n",
    "    args = (\n",
    "        np.array(df_happiness |> drop(['happiness', 'country'])), \n",
    "        np.array(df_happiness['happiness']), \n",
    "        0.1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.43997501,  0.52188498,  0.43554025, -0.10484642])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_result['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.4448321376528055, array([ 0.52188497,  0.43554027, -0.10484641]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = Ridge(alpha = 0.1)\n",
    "\n",
    "ridge.fit(\n",
    "    X = df_happiness.drop(columns=['happiness', 'country']),\n",
    "    y = df_happiness['happiness']\n",
    ")\n",
    "\n",
    "ridge.intercept_, ridge.coef_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "book-of-models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
